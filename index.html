<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- <link rel="stylesheet" type="text/css" href="/css/matery.css"> -->
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>Hamish的科研blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content>
    <meta property="og:type" content="website">
<meta property="og:title" content="Hamish的科研blog">
<meta property="og:url" content="https://sherlockbear.github.io/index.html">
<meta property="og:site_name" content="Hamish的科研blog">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hamish的科研blog">
    
        <link rel="alternate" type="application/atom+xml" title="Hamish的科研blog" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/avatar.jpg">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    

    
</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading" class="active"></div>

    <aside id="menu"  >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Kang Yachen</h5>
          <a href="mailto:kangyachen@westlake.edu.cn" title="kangyachen@westlake.edu.cn" class="mail">kangyachen@westlake.edu.cn</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect active">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/sherlockbear" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Hamish的科研blog</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header index-header">

    <div class="container fade-scale">
        <h1 class="title">Hamish的科研blog</h1>
        <h5 class="subtitle">
            
                
            
        </h5>
    </div>

    


</header>

<div class="container body-wrap">

    <ul class="post-list">
    
        <li class="post-list-item fade">
            <article id="post-Reinforcement-Learning-Reading-List"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2020-03-06 09:44:37" datetime="2020-03-06T01:44:37.000Z"  itemprop="datePublished">2020-03-06</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Reading-List/">Reading List</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2020/03/06/Reinforcement-Learning-Reading-List/">Reinforcement Learning Reading List（持续更新）</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <p>2020年初顶会论文中关于强化学习的论文列表，大部分应都有收录，如有缺漏，感谢指正。</p>
    

        <a href="/2020/03/06/Reinforcement-Learning-Reading-List/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Reinforcement-Learning/">Reinforcement Learning</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-Reinforcement-Learning-with-Competitive-Ensembles-of-Information-Constrained-Primitives"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2020-02-17 11:25:52" datetime="2020-02-17T03:25:52.000Z"  itemprop="datePublished">2020-02-17</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/paper翻译/">paper翻译</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2020/02/17/Reinforcement-Learning-with-Competitive-Ensembles-of-Information-Constrained-Primitives/">Reinforcement Learning with Competitive Ensembles of Information-Constrained Primitives</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要:"></a><strong>摘要:</strong></h3><p>在各种复杂环境中运行的强化学习智能体可以从其行为的结构分解中受益。通常，这是在分层强化学习的语境下解决的，往往目标是将策略分解为较低级别的原语或选项，同时较高级别的元策略针对给定情况触发适当的行为。但是，元策略仍必须在所有状态中做出适当的决定。在这项工作中，我们提出了一种策略设计，该策略设计可分解为原语，类似于分层强化学习，但没有高级元策略。相反，每个原语可以自己决定是否希望在当前状态下执行操作。我们使用信息论机制来实现此分散决策：每个原语都会选择需要多少有关当前状态的信息以做出决定，请求有关当前状态最多信息的原语被选择与环境交互。对原语进行正则化以使用尽可能少的信息，从而导致自然竞争和特异化。我们通过实验证明，该策略体系结构在泛化方面比平面策略和分层策略都有所改进。</p>
    

        <a href="/2020/02/17/Reinforcement-Learning-with-Competitive-Ensembles-of-Information-Constrained-Primitives/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Reinforcement-Learning/">Reinforcement Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Skill-Learning/">Skill Learning</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-NAS-Reading-List"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2019-12-05 15:31:04" datetime="2019-12-05T07:31:04.000Z"  itemprop="datePublished">2019-12-05</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Reading-List/">Reading List</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2019/12/05/NAS-Reading-List/">NAS Reading List</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <h2 id="NAS"><a href="#NAS" class="headerlink" title="NAS"></a>NAS</h2><ul>
<li>[x] （ICLR2017, google brain）Neural architecture search with reinforcement learning</li>
<li>[ ] （2019.11）Meta-Learning of Neural Architectures for Few-Shot Learning，meta与NAS的结合：<a href="https://arxiv.org/abs/1911.11090v1" target="_blank" rel="noopener">https://arxiv.org/abs/1911.11090v1</a></li>
<li><p>[x] （2019.01）Designing neural networks through neuroevolution，NE方法综述</p>
</li>
<li><p>（2017.09）Evolution Strategies as a Scalable Alternative to Reinforcement Learning <a href="https://openai.com/blog/evolution-strategies/" target="_blank" rel="noopener">https://openai.com/blog/evolution-strategies/</a>， <a href="https://arxiv.org/abs/1703.03864" target="_blank" rel="noopener">https://arxiv.org/abs/1703.03864</a>：NES方法与DQN、A3C相匹敌（但未完全脱离梯度）</p>
</li>
<li><p>（2018.04）Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning <a href="https://arxiv.org/abs/1712.06567" target="_blank" rel="noopener">https://arxiv.org/abs/1712.06567</a>：gradient-free的NE方法与DQN、A3C相匹敌</p>
</li>
<li><p>（2018.04）Simple random search provides a competitive approach to reinforcement learning <a href="https://arxiv.org/abs/1803.07055" target="_blank" rel="noopener">https://arxiv.org/abs/1803.07055</a>：简化NE方法（RS方法）与RPO、PPO、DDPG相匹敌</p>
</li>
</ul>
<h3 id="结合基于梯度的方法和神经进化"><a href="#结合基于梯度的方法和神经进化" class="headerlink" title="结合基于梯度的方法和神经进化"></a>结合基于梯度的方法和神经进化</h3><ul>
<li><p>（2018.05）Safe Mutations for Deep and Recurrent Neural Networks through Output Gradients <a href="https://arxiv.org/abs/1712.06563" target="_blank" rel="noopener">https://arxiv.org/abs/1712.06563</a>：保存状态与动作之间的关系库</p>
</li>
<li><p>（ICLR 2018.05）Policy Optimization by Genetic Distillation <a href="https://arxiv.org/abs/1711.01012" target="_blank" rel="noopener">https://arxiv.org/abs/1711.01012</a>：Genetic policy optimization</p>
</li>
<li><p>（ICLR 2018）Noisy Networks for Exploration <a href="https://arxiv.org/abs/1706.10295" target="_blank" rel="noopener">https://arxiv.org/abs/1706.10295</a></p>
</li>
<li><p>（ICLR 2018）Parameter space noise for exploration <a href="https://arxiv.org/abs/1706.01905" target="_blank" rel="noopener">https://arxiv.org/abs/1706.01905</a></p>
</li>
</ul>
<h3 id="新一代进化算法"><a href="#新一代进化算法" class="headerlink" title="新一代进化算法"></a>新一代进化算法</h3><ul>
<li><p>The Surprising Creativity of Digital Evolution: A Collection of Anecdotes from the Evolutionary Computation and Artificial Life Research Communities <a href="https://arxiv.org/abs/1803.03453" target="_blank" rel="noopener">https://arxiv.org/abs/1803.03453</a> ：综述</p>
</li>
<li><p>（NIPS 2018）Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents <a href="https://arxiv.org/abs/1712.06560" target="_blank" rel="noopener">https://arxiv.org/abs/1712.06560</a></p>
</li>
<li><p>（NIPS workshop 2018）Deep Curiosity Search: Intra-Life Exploration Can Improve Performance on Challenging Deep Reinforcement Learning Problems <a href="https://arxiv.org/abs/1806.00553" target="_blank" rel="noopener">https://arxiv.org/abs/1806.00553</a></p>
</li>
</ul>
<h3 id="架构进化"><a href="#架构进化" class="headerlink" title="架构进化"></a>架构进化</h3><ul>
<li><p>From Nodes to Networks: Evolving Recurrent Neural Networks <a href="https://arxiv.org/abs/1803.04439" target="_blank" rel="noopener">https://arxiv.org/abs/1803.04439</a></p>
</li>
<li><p>（AAAI 2019）Regularized Evolution for Image Classifier Architecture Search <a href="https://arxiv.org/abs/1802.01548" target="_blank" rel="noopener">https://arxiv.org/abs/1802.01548</a></p>
</li>
</ul>

    

        <a href="/2019/12/05/NAS-Reading-List/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NAS/">NAS</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-Neural-Architecture-Search-with-Reinforcement-Learning"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2019-12-03 10:26:34" datetime="2019-12-03T02:26:34.000Z"  itemprop="datePublished">2019-12-03</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/paper翻译/">paper翻译</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2019/12/03/Neural-Architecture-Search-with-Reinforcement-Learning/">Neural Architecture Search with Reinforcement Learning</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要:"></a><strong>摘要:</strong></h3><p>神经网络是一种功能强大、灵活的模型，在图像、语音和自然语言理解等许多困难的学习任务中起着很好的作用。尽管取得了成功，神经网络仍然很难设计。在本文中，我们使用递归网络来生成神经网络的模型描述，并利用强化学习来训练该RNN，最大化所生成的架构在验证集上的期望精度。在CIFAR-10数据集上，我们的方法可以从头开始，设计一种新的网络体系结构，在测试集精度方面可以与人类发明的最佳体系结构相媲美。我们的CIFAR-10模型的测试错误率为3.65，比以前使用类似架构方案的最新模型高0.09%，快1.05倍。在Penn Treebank数据集上，我们的模型可以组成一个新的递归单元，其性能优于广泛使用的LSTM单元和其他SOTA baseline。我们的单元在Penn Treebank上达到了测试集62.4的困惑度，这比之前的SOTA模型在困惑度上好3.6。该单元还可以转移到PTB上的字符语言建模任务，并达到SOTA的1.214困惑度。</p>
    

        <a href="/2019/12/03/Neural-Architecture-Search-with-Reinforcement-Learning/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NAS/">NAS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Reinforcement-Learning/">Reinforcement Learning</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-Meta-World-A-Benchmark-and-Evaluation-for-Multi-Task-and-Meta-Reinforcement-Learning"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2019-11-01 15:24:27" datetime="2019-11-01T07:24:27.000Z"  itemprop="datePublished">2019-11-01</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/paper翻译/">paper翻译</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2019/11/01/Meta-World-A-Benchmark-and-Evaluation-for-Multi-Task-and-Meta-Reinforcement-Learning/">Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要:"></a><strong>摘要:</strong></h3><p>元强化学习算法可以通过利用先前的经验来学习如何学习，从而使机器人更快地掌握新技能。但是，当前有关元强化学习的许多研究都集中在非常狭窄的任务分布上。例如，一个常用的元强化学习基准将模拟机器人的不同的运行速度作为不同的任务。当在这样狭窄的任务分布上进行策略的元训练时，它们可能无法泛化到更快地获取全新的任务。因此，如果这些方法的目的是能够更快地获取全新的行为，则我们必须在足够广泛的任务分布上评估它们，以使其能够推广到新的行为。在本文中，我们提出了一种用于元强化学习和多任务学习的开源模拟benchmark，该benchmark包含50个不同的机器人操纵任务。我们的目标是使开发用于加速获取全新的、可执行的任务的算法成为可能。我们针对这些任务评估了6种最新的元强化学习和多任务学习算法。令人惊讶的是，尽管每项任务及其变体（例如，不同的对象位置）都可以合理地成功学习，但是这些算法难以同时学习多个任务，即使只有十个不同的训练任务也是如此。我们的分析和开源环境为将来的多任务学习和元学习研究铺平了道路，这些研究可以实现有意义的泛化，从而释放这些方法的全部潜力。</p>
<p>benchmark任务的视频在项目页面上：<a href="https://meta-world.github.io" target="_blank" rel="noopener">meta-world.github.io</a>。我们的开源代码可在以下网址获得：<a href="https://github.com/rlworkgroup/metaworld" target="_blank" rel="noopener">https://github.com/rlworkgroup/metaworld</a></p>
    

        <a href="/2019/11/01/Meta-World-A-Benchmark-and-Evaluation-for-Multi-Task-and-Meta-Reinforcement-Learning/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/benchmark/">benchmark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/meta-learning/">meta-learning</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-iMAML笔记（翻译）"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2019-10-18 15:45:27" datetime="2019-10-18T07:45:27.000Z"  itemprop="datePublished">2019-10-18</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/blog翻译/">blog翻译</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2019/10/18/iMAML笔记（翻译）/">iMAML笔记（翻译）[更新中]</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <p>转载并翻译iMAML的阅读笔记</p>
    

        <a href="/2019/10/18/iMAML笔记（翻译）/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MAML/">MAML</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/meta-learning/">meta-learning</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-On-First-Order-Meta-Learning-Algorithms"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2019-10-17 10:58:41" datetime="2019-10-17T02:58:41.000Z"  itemprop="datePublished">2019-10-17</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/paper翻译/">paper翻译</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2019/10/17/On-First-Order-Meta-Learning-Algorithms/">On First-Order Meta-Learning Algorithms</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要:"></a><strong>摘要:</strong></h3><p>本文考虑了存在任务分布的元学习问题，并且我们希望获得一个从该分布中采样到以前没有见过的任务时表现良好（即快速学习）的agent。我们分析了一族用于学习参数初始化的算法，可以在新任务上进行快速微调，仅使用一阶导数进行元学习更新。该族包括并推广了一阶MAML，它是通过忽略二阶导数获得的MAML的近似值。它还包括Reptile，这是我们在此处引入的新算法，该算法通过重复采样任务，对其进行训练并将初始化朝着该任务的训练权重进行工作。我们扩展了Finn等人的结果。说明一阶元学习算法在一些公认的针对少数镜头分类的基准上表现良好，并且我们提供了旨在理解这些算法为何起作用的理论分析。</p>

    

        <a href="/2019/10/17/On-First-Order-Meta-Learning-Algorithms/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MAML/">MAML</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/meta-learning/">meta-learning</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-Meta-Learning-A-Survey"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2019-10-09 20:37:57" datetime="2019-10-09T12:37:57.000Z"  itemprop="datePublished">2019-10-09</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/paper翻译/">paper翻译</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2019/10/09/Meta-Learning-A-Survey/">Meta-Learning: A Survey[更新中]</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要:"></a><strong>摘要:</strong></h3><p>元学习或学会学习是系统地观察不同机器学习方法如何在广泛的学习任务中执行的科学，然后从这种经验或元数据中学习，以比其他方式更快地学习新任务 。<br>这不仅极大地加速和改进了机器学习流程或神经网络架构的设计，还使我们能够用数据驱动方式学习的新方法取代手工设计算法。<br>在本章中，我们将概述这个迷人且不断发展的领域的最新技术。</p>
    

        <a href="/2019/10/09/Meta-Learning-A-Survey/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Survey/">Survey</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/meta-learning/">meta-learning</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-Learning-to-Learn-via-Self-Critique"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2019-10-09 20:33:12" datetime="2019-10-09T12:33:12.000Z"  itemprop="datePublished">2019-10-09</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/paper翻译/">paper翻译</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2019/10/09/Learning-to-Learn-via-Self-Critique/">Learning to Learn via Self-Critique</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要:"></a><strong>摘要:</strong></h3><p>在少样本学习中，机器学习系统从一小组与特定任务有关的有标签样本中学习，从而可以推广到同一任务的新示例。鉴于此类任务中有标签样本的数量有限，我们希望充分利用所有可能的信息。通常，模型从小型训练集（support-set）中学习任务特定的信息，以对无标签验证集（target-set也叫query-set）进行预测。target-set包含其他特定于任务的信息，而现有的少样本学习方法并未利用这些信息。通过transductive learning来使用target-set样本需要更先进的方法；at inference time, the target-set contains only unlabelled input data-points, and so discriminative learning cannot be used。在本文中，我们提出了一个名为“Self-Critique and Adapt”或SCA的框架，该框架可以学习无标签损失函数，该函数被参数化为神经网络。基本模型使用现有方法（例如，随机梯度下降与交叉熵损失相结合）在支持集上学习，然后使用学习到的损失函数针对传入的target-task进行更新。学习无标签损失函数，以便target-set-updated模型实现更高的泛化性能。实验表明，与仅适用于支持集的基准相比，SCA可以显着降低错误率，并可以在Mini-ImageNet和Caltech-UCSD Birds 200上获得最先进的基准性能。</p>
    

        <a href="/2019/10/09/Learning-to-Learn-via-Self-Critique/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/meta-learning/">meta-learning</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-HOW-TO-TRAIN-YOUR-MAML"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2019-10-09 20:31:44" datetime="2019-10-09T12:31:44.000Z"  itemprop="datePublished">2019-10-09</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/paper翻译/">paper翻译</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2019/10/09/HOW-TO-TRAIN-YOUR-MAML/">HOW TO TRAIN YOUR MAML</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要:"></a><strong>摘要:</strong></h3><p>少样本学习领域最近有了长足的进步。这些进步中的大多数来自将少样本学习构建为元学习问题。目前，Model Agnostic Meta Learning或MAML是通过元学习进行少样本学习的最佳方法之一。MAML简单，优雅且功能强大，但是它具有许多问题，例如对神经网络结构非常敏感，通常会导致训练过程中的不稳定，需要艰巨的超参数搜索来稳定训练并实现高泛化，在训练和推理时都非常耗费算力。在本文中，我们提出了对MAML的各种修改，这些修改不仅可以稳定系统，而且可以大大提高MAML的泛化性能，收敛速度和计算开销，我们称之为MAML++。</p>
    

        <a href="/2019/10/09/HOW-TO-TRAIN-YOUR-MAML/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MAML/">MAML</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/meta-learning/">meta-learning</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-META-LEARNING-WITH-LATENT-EMBEDDING-OPTIMIZATION"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2019-10-09 20:27:13" datetime="2019-10-09T12:27:13.000Z"  itemprop="datePublished">2019-10-09</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/paper翻译/">paper翻译</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2019/10/09/META-LEARNING-WITH-LATENT-EMBEDDING-OPTIMIZATION/">META-LEARNING WITH LATENT EMBEDDING OPTIMIZATION</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要:"></a><strong>摘要:</strong></h3><p>基于梯度的元学习技术在解决具有挑战性的少样本学习和快速适应问题方面有着广泛的应用和实用价值。然而，它们在极端低数据状态下在高维参数空间上操作时存在实际困难。我们表明，有可能通过学习到一个模型参数的依赖数据的潜在生成表示，并在此低维潜在空间中执行基于梯度的元学习，从而绕过这些限制。最终的方法，latent embedding optimization（LEO），将基于梯度的自适应过程与模型参数的底层高维空间解耦。我们的评估表明，LEO可以在竞争激烈的miniImageNet和tieredImageNet少样本分类任务中达到最先进的性能。进一步的分析表明，LEO能够捕获数据中的不确定性，并能通过在潜在空间中进行优化，更有效地进行适应。</p>
    

        <a href="/2019/10/09/META-LEARNING-WITH-LATENT-EMBEDDING-OPTIMIZATION/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/meta-learning/">meta-learning</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-Meta-Learning-with-Implicit-Gradients"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2019-10-09 20:26:02" datetime="2019-10-09T12:26:02.000Z"  itemprop="datePublished">2019-10-09</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/paper翻译/">paper翻译</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2019/10/09/Meta-Learning-with-Implicit-Gradients/">Meta-Learning with Implicit Gradients</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要:"></a><strong>摘要:</strong></h3><p>智能系统的一个核心功能是能够通过借鉴先前的经验来快速学习新任务的能力。最近，基于梯度（或优化）的元学习已成为一种有效的少样本学习方法。在此形式中，仅使用当前任务中的少量数据，即可在outer loop中学习元参数，而在inner-loop中学习特定于任务的模型。扩展这些方法的关键挑战是需要通过inner-loop学习过程计算微分，这可能会带来相当大的计算和内存负担。借助隐式微分，我们开发了隐式MAML算法，该算法仅取决于inner level优化的解，而不取决于inner loop优化器采用的路径。这有效地将元梯度计算与inner loop优化器的选择解耦。因此，我们的方法与inner loop优化器的选择无关，并且可以优雅地处理许多梯度步骤而不会梯度消失或内存限制。从理论上讲，我们证明隐式MAML可以使用不超过计算单个内循环梯度所需的内存占用量来计算准确的元梯度，而不会增加总的计算成本。从实验上，我们证明了隐式MAML的这些好处可转化为在少样本的图像识别benchmarks上的经验收益。</p>
<p>其他来源：<a href="https://www.inference.vc/notes-on-imaml-meta-learning-without-differentiating-through/" target="_blank" rel="noopener">Notes on iMAML: Meta-Learning with Implicit Gradients</a></p>
<p>对这篇笔记也进行了翻译，链接如下: <a href="https://sherlockbear.github.io/2019/10/18/iMAML%E7%AC%94%E8%AE%B0%EF%BC%88%E7%BF%BB%E8%AF%91%EF%BC%89/">iMAML笔记（翻译）</a></p>
    

        <a href="/2019/10/09/Meta-Learning-with-Implicit-Gradients/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MAML/">MAML</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/meta-learning/">meta-learning</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-Meta-Learning-with-Differentiable-Convex-Optimization"
  class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2019-10-09 20:19:00" datetime="2019-10-09T12:19:00.000Z"  itemprop="datePublished">2019-10-09</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/paper翻译/">paper翻译</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2019/10/09/Meta-Learning-with-Differentiable-Convex-Optimization/">Meta-Learning with Differentiable Convex Optimization</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        <h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要:"></a><strong>摘要:</strong></h3><p>少样本学习的许多元学习方法都依赖于简单的基础学习器，例如最近邻分类器。但是，即使在少样本情况下，经过判别训练的线性判别器可以提供更好的泛化能力。我们建议使用这些判别器作为基础学习器，以学习少样本学习的表示形式，并表明它们在一系列少样本识别benchmarks中提供了特征尺寸和性能之间的更好权衡。我们的目标是学习在线性分类规则下对新类别很好地泛化的特征嵌入。为了有效地解决该目标，我们利用线性分类器的两个属性：凸问题的最优性条件的隐式微分和优化问题的对偶表示。这使我们可以在计算开销适度增加的情况下使用具有更高泛化性的高维嵌入。我们的方法名为MetaOptNet，可在miniImageNet，tieredImageNet，CIFAR-FS和FC100一次性学习基准上获得最先进的性能。代码可以在<a href="https://github.com/kjunelee/MetaOptNet" target="_blank" rel="noopener">这里</a>找到</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://res.cloudinary.com/dyxexppyu/image/upload/v1570623069/wps_2019-09-30_16-53-43_ri1avv.png" alt title>
                </div>
                <div class="image-caption"></div>
            </figure>
    

        <a href="/2019/10/09/Meta-Learning-with-Differentiable-Convex-Optimization/" class="post-more waves-effect waves-button">
            阅读全文…
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/meta-learning/">meta-learning</a></li></ul>

    </div>
    
</article>

        </li>
    
    </ul>

    

</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>Kang Yachen &copy; 2015 - 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://sherlockbear.github.io/&title=Hamish的科研blog&pic=https://sherlockbear.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://sherlockbear.github.io/&title=Hamish的科研blog&source=" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://sherlockbear.github.io/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=Hamish的科研blog&url=https://sherlockbear.github.io/&via=https://sherlockbear.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://sherlockbear.github.io/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAABu0lEQVR42u3aQY7DIAwF0Nz/0pntSDOl3xhQWj1WWaTk0YVlG19XvO7h+v3O3/fHu107Fi4ubptbpYw/nO8w/tXLI+Hi4h7kvqJUA1NOz/8OXFzcT+F2KLi4uN/EHT8nB8PFxf0sblL8rGpzJGFxQa2Gi4vb4OYf2Pe8pb+Li4s7xb0bKw9Pc8Hrny/i4uIe4VaDTudI4zKpUBrh4uJu5nZGKJJkaHzUajMFFxf3JDdvnnZSn85hcHFxz3NzRDV9yROa6B1cXNzj3OqIVRXdD3m4uLhP4HaGNTspVLlWw8XFXcpdVaLMtVbLI1m4uLhHuPnnqwlQP2xFtRouLu4RbhXduSzJRzcmoykuLu5Sbo7OM6kq9+WcCC4u7mZu+dX4kPk8dnnsAxcXdzM3SUTm2qmd5umb4gcXF3czN09iqo2SfKAzD5S4uLhnuHdxVRsZ+Q5JWYWLi3uGm6+5a5LkMHMJEC4u7m5u3jatjlnkF6uFqxdcXNyD3FWjWnNXKYWgiYuL+zBuP8BVr3DedHFwcXEfwF11vM5ABi4u7kluXvxUR7jytkshxcHFxd3MndturpHaHwvDxcXdzP0B8B3yWXoVzyoAAAAASUVORK5CYII=" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: false };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->





</body>
</html>
